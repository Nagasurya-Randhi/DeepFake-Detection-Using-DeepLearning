# DeepFake-Detection-Using-DeepLearning

## Introduction -
DeepFakes are synthetic images or videos generated to modify existing images or videos to fit the purpose of an individual/entity. DeepFakes, though quite useful for individual privacy protection and movie editing, has often found itself being implemented for fraudulent and defamation activities. In our project, we are addressing one of these issues i.e. defamation. We are attempting to create a model that will successfully detect a deep fake video and mark the video as tampered-with, in case of a Deepfake. The bigger picture we are looking at is fake news and rumors generated from these deep fakes. Their capability to influence the elections via social media is quite evident from past incidents. We are tackling the visual deep fake aspect of this problem.It was the motivation behind using the CelebDF dataset for our project. Our focus lies in creating a highly efficient model that detects deep fakes in a video. While detecting these deep fakes is not particularly easy, it is a more arduous task when video instead of images are involved. The existing research in this field majorly relates to deep fakes in images and very little work has been done on videos. Moreover, quite a few of those instances are cover the theoretical aspect of how one can possibly approach the issue. Our paper discusses how different models should be put together and makes use of pre-trained models to get better accuracy. Our approach involves starting with vanilla CNN models and moving up the accuracy order by using CNN transfer learning coupled with RNNs to capture temporal natures of the video frames. The results are interesting as they showcase how the use of RNNs can alter results in such problem statements in comparison to using standalone CNNs. Despite this the architecture of CNN plays a key role not only in computation power but also final accuracy of the model.

## Dataset Used -
  We are using the Celeb-DF dataset.
  Link to the dataset :
  1.**https://drive.google.com/drive/folders/1SxCb_Wr7N4Wsc-uvjUl0i-6PpwYmwN65**.
  2.**https://drive.google.com/drive/folders/1g97v9JoD3pCKA2TxHe8ZLRe4buX2siCQ**

It is a large-scale challenging dataset for deepfake forensics. It includes 479 original videos and 455 corresponding DeepFake videos.The videos consists cropped celebrity faces. The real source videos are based on publicly available YouTube video clips of 59 celebrities of diverse genders, ages, and ethic groups. The DeepFake videos are generated using an improved DeepFake synthesis method. As a result, the overall visual quality of the synthesized DeepFake videos in Celeb-DF is greatly improved when compared to existing datasets, with significantly fewer notable visual artifacts. The features of the dataset are the videos and a label of -fake/real.

## Model Architecture Definitions -
For this project 3 different models are implemented and results are compared.The approach was to build from a baseline architecture and move towards more complex architectures. The transfer learning mechanism is used by using pretrained models.

### Model 1 : CNN Architecture
CNN learns the image features through various convolution layers, activation layers, pooling layers and fully connected layers to produce an output. To get a baseline performance for the projec CNN was used to classify videos into Real or Fake like an image classification problem.To make it work for videos we improvised the input by extracting a sequence of frames from each video. These frames were together and fed to the model.The results for the given sequence of frames were averaged out to get the final output for the video.

### Model 2 : ResNeXt + LSTM
For the second model,the coupling of a CNN architecture and a Recurrent Neural Network was used with the aim that the CNN part of the model perform will feature extraction and the RNN part will relate those features. The ResNext pretrained model stacked with LSTM was used.To be precise the pre-trained model resnext50 32x4d was implement.It is a 50 layered convolution network which is divided into 32 paths and with bottleneck width 4 i.e. the shape of the residual block is 32x4. It consists of 25M parameters.ResNext was chosen because ,as given the large size of the dataset,it could result in a significant computation reductions. Long Short-Term Memory (LSTM) networks are a type of recurrent neural network capable of learning order dependence in sequence prediction problems.Here, in this model, the stack of frames is passed as input to the model and the feature map from the ResNext of these frames is fed into the LSTM.

### Model 3 : EfficientNet+GRU
EfficientNet is considered the most powerful CNNs. EfficientNet uses a novel model scaling method that uses a simple yet highly effective compound coefficient to scale up CNNs in a more structured manner. The conventional practice for model scaling is to arbitrarily increase the CNN depth or width, or to use larger input image resolution for training and evaluation. While these methods do improve accuracy, they usually require tedious manual tuning, and still often yield suboptimal performance. The EfficientNet model -’EfficientNet-B0’ is utilizied as the baseline network, pre trained to the ImageNet dataset with 2 layers of Gated Recurrent Units (GRU). EfficientNet-B0 consits of 5.3M parameters which is a significant reduction from ResNext and hence reduces computational costs further. GRUs are improved version of standard recurrent neural network. To solve the vanishing gradient problem of a standard RNN, GRU uses, so-called, update gate and reset gate. GRU can also be considered as a variation on the LSTM because both are designed similarly .The special thing about them is that they can be trained to keep information from long ago, without washing it through time or remove information which is irrelevant to the prediction.
